import os
import torch
import numpy as np
import streamlit as st  # âœ… Streamlit ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€
from PIL import Image
from torchvision import transforms
from scripts.Embedding import Embedding
from scripts.text_proxy import TextProxy
from scripts.ref_proxy import RefProxy
from scripts.sketch_proxy import SketchProxy
from scripts.bald_proxy import BaldProxy
from scripts.color_proxy import ColorProxy
from scripts.feature_blending import hairstyle_feature_blending
from utils.seg_utils import vis_seg
from utils.mask_ui import painting_mask
from utils.image_utils import display_image_list, process_display_input
from utils.model_utils import load_base_models
from utils.options import Options

# âœ… ë””ë°”ì´ìŠ¤ ìë™ ì„¤ì •
device = torch.device("mps" if torch.backends.mps.is_available() else "cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… Using device: {device}")

# âœ… ì´ë¯¸ì§€ ë³€í™˜ ì„¤ì •
image_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
])

def hairstyle_editing_pipeline(src_name, global_cond=None, local_sketch=False, paint_the_mask=False):
    """
    í—¤ì–´ìŠ¤íƒ€ì¼ í¸ì§‘ì„ ìˆ˜í–‰í•˜ëŠ” í•¨ìˆ˜ (Streamlitì—ì„œ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•˜ë„ë¡ ìˆ˜ì •)
    """
    # âœ… Streamlit ì§„í–‰ ìƒíƒœ í‘œì‹œ (í…ìŠ¤íŠ¸ + í”„ë¡œê·¸ë ˆìŠ¤ ë°”)
    status_text = st.empty()
    progress_bar = st.progress(0)

    # âœ… ì˜µì…˜ ë¡œë“œ
    status_text.text("ğŸ“Œ ì˜µì…˜ ë¡œë“œ ì¤‘...")
    opts = Options().parse(jupyter=True)
    progress_bar.progress(10)

    # âœ… ê¸°ë³¸ ëª¨ë¸ ë¡œë“œ
    status_text.text("ğŸ“Œ ëª¨ë¸ ë¡œë”© ì¤‘...")
    g_ema, mean_latent_code, seg = load_base_models(opts)
    ii2s = Embedding(opts, g_ema, mean_latent_code[0, 0])
    progress_bar.progress(30)

    # âœ… Latent ì €ì¥ ê²½ë¡œ í™•ì¸ ë° ìƒì„±
    latent_path = os.path.join(opts.src_latent_dir, f"{src_name}.npz")
    if not os.path.isfile(latent_path):
        status_text.text("ğŸ“Œ ì´ë¯¸ì§€ ì„ë² ë”© ìƒì„± ì¤‘...")
        inverted_latent_w_plus, inverted_latent_F = ii2s.invert_image_in_FS(image_path=f'{opts.src_img_dir}/{src_name}.jpg')
        np.savez(latent_path, latent_in=inverted_latent_w_plus.detach().to(device).numpy(),
                 latent_F=inverted_latent_F.detach().to(device).numpy())
    progress_bar.progress(50)

    # âœ… Latent ë¡œë“œ
    status_text.text("ğŸ“Œ Latent ë°ì´í„° ë¡œë”© ì¤‘...")
    src_latent = torch.from_numpy(np.load(latent_path)['latent_in']).to(device)
    src_feature = torch.from_numpy(np.load(latent_path)['latent_F']).to(device)
    progress_bar.progress(60)

    # âœ… ì›ë³¸ ì´ë¯¸ì§€ ë° ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ ì¤€ë¹„
    status_text.text("ğŸ“Œ ì›ë³¸ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘...")
    src_image = image_transform(Image.open(f'{opts.src_img_dir}/{src_name}.jpg').convert('RGB')).unsqueeze(0).to(device)
    input_mask = torch.argmax(seg(src_image)[1], dim=1).long().clone().detach().to(device)
    progress_bar.progress(70)

    # âœ… í”„ë¡ì‹œ ìƒì„±
    status_text.text("ğŸ“Œ ë³€í˜• ëª¨ë¸ ë¡œë”© ì¤‘...")
    bald_proxy = BaldProxy(g_ema, opts.bald_path)
    text_proxy = TextProxy(opts, g_ema, seg, mean_latent_code)
    ref_proxy = RefProxy(opts, g_ema, seg, ii2s)
    sketch_proxy = SketchProxy(g_ema, mean_latent_code, opts.sketch_path)
    color_proxy = ColorProxy(opts, g_ema, seg)
    progress_bar.progress(80)

    # âœ… í—¤ì–´ìŠ¤íƒ€ì¼ í¸ì§‘
    status_text.text("ğŸ“Œ í—¤ì–´ìŠ¤íƒ€ì¼ ë³€ê²½ ì¤‘...")
    latent_global, latent_local, latent_bald, local_blending_mask, painted_mask = None, None, None, None, None

    if paint_the_mask:
        modified_mask = painting_mask(input_mask)
        input_mask = torch.from_numpy(modified_mask).unsqueeze(0).to(device).long().clone().detach()
        vis_modified_mask = vis_seg(modified_mask)
        display_image_list([src_image, vis_modified_mask])
        painted_mask = input_mask

    if local_sketch:
        latent_local, local_blending_mask, visual_local_list = sketch_proxy(input_mask)
        display_image_list(visual_local_list)

    if global_cond is not None:
        assert isinstance(global_cond, str)

        latent_bald, visual_bald_list = bald_proxy(src_latent)
        display_image_list(visual_bald_list)

        if global_cond.endswith('.jpg') or global_cond.endswith('.png'):
            latent_global, visual_global_list = ref_proxy(global_cond, src_image, painted_mask=painted_mask)
        else:
            latent_global, visual_global_list = text_proxy(global_cond, src_image, from_mean=True, painted_mask=painted_mask)
        display_image_list(visual_global_list)

    # âœ… ìµœì¢… ì´ë¯¸ì§€ ìƒì„±
    src_feature, edited_hairstyle_img = hairstyle_feature_blending(
        g_ema, seg, src_latent, src_feature, input_mask,
        latent_bald=latent_bald, latent_global=latent_global,
        latent_local=latent_local, local_blending_mask=local_blending_mask
    )

    progress_bar.progress(100)
    status_text.text("âœ… í—¤ì–´ìŠ¤íƒ€ì¼ ë³€ê²½ ì™„ë£Œ!")

    return process_display_input(edited_hairstyle_img)